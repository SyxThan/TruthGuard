{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý 8741 mẫu...\n",
      "Hoàn thành! Còn lại 8715 mẫu sau khi xử lý.\n",
      "Đang xử lý 486 mẫu...\n",
      "Hoàn thành! Còn lại 486 mẫu sau khi xử lý.\n",
      "\n",
      "Đang tạo TF-IDF Features...\n",
      "Đang lưu TF-IDF Vectorizer vào 'tfidf_vectorizer.pkl'...\n",
      "Lưu Vectorizer hoàn tất.\n",
      "\n",
      "--- Mô hình 1: Logistic Regression ---\n",
      "Đang huấn luyện Logistic Regression...\n",
      "Logistic Regression huấn luyện hoàn tất.\n",
      "Đang lưu mô hình Logistic Regression vào 'logreg_fake_news_model.pkl'...\n",
      "Lưu mô hình Logistic Regression hoàn tất.\n",
      "\n",
      "--- Mô hình 2: Linear SVM ---\n",
      "Đang huấn luyện Linear SVM...\n",
      "Linear SVM huấn luyện hoàn tất.\n",
      "Đang lưu mô hình Linear SVM vào 'svm_fake_news_model.pkl'...\n",
      "Lưu mô hình Linear SVM hoàn tất.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib # Thêm thư viện joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================================================================\n",
    "# BƯỚC 1: TẢI DỮ LIỆU\n",
    "# ===================================================================\n",
    "\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "val_df = pd.read_csv('dataset/val.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Loại bỏ các cột không cần thiết\n",
    "cols_to_drop = ['user_name', 'timestamp_post', 'num_like_post', 'num_comment_post', 'num_share_post']\n",
    "train_df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "val_df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test_df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# BƯỚC 2: HÀM TIỀN XỬ LÝ (PREPROCESSING FUNCTIONS)\n",
    "# ===================================================================\n",
    "\n",
    "def remove_emoji(text):\n",
    "    \"\"\"Loại bỏ emoji\"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Làm sạch văn bản tiếng Việt\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = remove_emoji(text)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|<url>', '', text, flags=re.MULTILINE) # URL\n",
    "    text = re.sub(r'\\S+@\\S+', '', text) # Email\n",
    "    text = re.sub(r'\\b\\d{10,11}\\b', '', text) # Số điện thoại\n",
    "    text = re.sub(r'<.*?>', '', text) # HTML\n",
    "    text = text.replace('_', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'[^a-zA-Z0-9àáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ\\s.,!?_-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def vietnamese_tokenize(text):\n",
    "    \"\"\"Tách từ tiếng Việt\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    try:\n",
    "        tokenized_text = word_tokenize(text, format=\"text\")\n",
    "        return tokenized_text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "VIETNAMESE_STOPWORDS= set([\n",
    "    'bị', 'bởi', 'cả', 'các', 'cái', 'cần', 'càng', 'chỉ', 'chiếc',\n",
    "    'cho', 'chứ', 'chưa', 'chuyện', 'có', 'có_thể', 'cứ', 'của',\n",
    "    'cùng', 'cũng', 'đã', 'đang', 'đây', 'để', 'đến_nỗi', 'đều',\n",
    "    'điều', 'do', 'đó', 'được', 'dưới', 'gì', 'khi', 'không',\n",
    "    'là', 'lại', 'lên', 'lúc', 'mà', 'mỗi', 'một_cách', 'này',\n",
    "    'nên', 'nếu', 'ngay', 'nhiều', 'như', 'nhưng', 'những', 'nơi',\n",
    "    'nữa', 'phải', 'qua', 'ra', 'rằng', 'rất', 'rồi', 'sau',\n",
    "    'sẽ', 'so', 'sự', 'tại', 'theo', 'thì', 'trên', 'trước',\n",
    "    'từ', 'từng', 'và', 'vẫn', 'vào', 'vậy', 'vì', 'việc',\n",
    "    'với', 'vừa', 'ai', 'anh', 'bao_giờ', 'bao_lâu', 'bao_nhiêu', 'bên', 'bộ',\n",
    "    'chị', 'chúng_ta', 'chúng_tôi', 'cuộc', 'em', 'hết', 'họ',\n",
    "    'hoặc', 'khác', 'kể', 'khiến', 'làm', 'loại', 'lòng', 'mình',\n",
    "    'muốn', 'người', 'nhà', 'nhất', 'nhỏ', 'những', 'năm', 'nào',\n",
    "    'này', 'nào', 'nếu', 'ông', 'qua', 'quá', 'quyển', 'sau_đó',\n",
    "    'thằng', 'thì', 'thứ', 'tin', 'tôi', 'tới', 'vài', 'vẫn',\n",
    "    'về', 'việc', 'vòng', 'xa', 'xuống', 'ý', 'đã', 'đem', 'đến',\n",
    "    'định', 'đó', 'đời', 'đồng_thời', 'để', 'đều', 'đi', 'điều',\n",
    "    'đơn_vị', 'được', 'gần', 'họ', 'giờ', 'hay', 'hơn', 'ít',\n",
    "    'liên_quan', 'lúc', 'lên', 'mấy', 'ngoài', 'nhiều', 'nhằm',\n",
    "    'như_vậy', 'phía', 'trong', 'tuy', 'từng', 'tới', 'về',\n",
    "    'với', 'xem'\n",
    "])\n",
    "\n",
    "def remove_stopwords(text, stopwords=VIETNAMESE_STOPWORDS):\n",
    "    \"\"\"Loại bỏ stopwords\"\"\"\n",
    "    if not text: return \"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def normalize_repeated_chars(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "\n",
    "def remove_extra_punctuation(text):\n",
    "    text = re.sub(r'[.]{2,}', '.', text)\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    return text\n",
    "\n",
    "def normalize_numbers(text):\n",
    "    return text\n",
    "\n",
    "def preprocess_pipeline(text, remove_stop=True):\n",
    "    text = clean_text(text)\n",
    "    text = normalize_repeated_chars(text)\n",
    "    text = remove_extra_punctuation(text)\n",
    "    text = vietnamese_tokenize(text)\n",
    "    if remove_stop:\n",
    "        text = remove_stopwords(text)\n",
    "    text = normalize_numbers(text)\n",
    "    return text\n",
    "\n",
    "def preprocess_dataframe(df, text_column='post_message', remove_stop=True):\n",
    "    print(f\"Đang xử lý {len(df)} mẫu...\")\n",
    "    df['cleaned_text'] = df[text_column].apply(\n",
    "        lambda x: preprocess_pipeline(x, remove_stop=remove_stop)\n",
    "    )\n",
    "    df = df[df['cleaned_text'].str.strip() != '']\n",
    "    print(f\"Hoàn thành! Còn lại {len(df)} mẫu sau khi xử lý.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# BƯỚC 3: ÁP DỤNG TIỀN XỬ LÝ\n",
    "# ===================================================================\n",
    "\n",
    "train_processed = preprocess_dataframe(train_df, remove_stop=False)\n",
    "test_processed = preprocess_dataframe(test_df, remove_stop=False)\n",
    "\n",
    "X_train = train_processed['cleaned_text']\n",
    "y_train = train_processed['label']\n",
    "X_test = test_processed['cleaned_text']\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# BƯỚC 4: TẠO FEATURE (TF-IDF)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\nĐang tạo TF-IDF Features...\")\n",
    "vectorizer = TfidfVectorizer(max_features=50000,\n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# --- THÊM BƯỚC LƯU VECTORIZER ---\n",
    "print(\"Đang lưu TF-IDF Vectorizer vào 'tfidf_vectorizer.pkl'...\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "print(\"Lưu Vectorizer hoàn tất.\")\n",
    "# --------------------------------\n",
    "\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# BƯỚC 5: XÂY DỰNG VÀ HUẤN LUYỆN MÔ HÌNH\n",
    "# ===================================================================\n",
    "\n",
    "## Mô hình 1: Logistic Regression\n",
    "print(\"\\n--- Mô hình 1: Logistic Regression ---\")\n",
    "logreg_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "print(\"Đang huấn luyện Logistic Regression...\")\n",
    "logreg_model.fit(X_train_vectorized, y_train)\n",
    "print(\"Logistic Regression huấn luyện hoàn tất.\")\n",
    "\n",
    "# --- THÊM BƯỚC LƯU MÔ HÌNH 1 ---\n",
    "print(\"Đang lưu mô hình Logistic Regression vào 'logreg_fake_news_model.pkl'...\")\n",
    "joblib.dump(logreg_model, \"logreg_fake_news_model.pkl\")\n",
    "print(\"Lưu mô hình Logistic Regression hoàn tất.\")\n",
    "# ------------------------------\n",
    "\n",
    "## Mô hình 2: Support Vector Machine (LinearSVC)\n",
    "print(\"\\n--- Mô hình 2: Linear SVM ---\")\n",
    "svm_model = LinearSVC(class_weight='balanced')\n",
    "print(\"Đang huấn luyện Linear SVM...\")\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "print(\"Linear SVM huấn luyện hoàn tất.\")\n",
    "\n",
    "# --- THÊM BƯỚC LƯU MÔ HÌNH 2 ---\n",
    "print(\"Đang lưu mô hình Linear SVM vào 'svm_fake_news_model.pkl'...\")\n",
    "joblib.dump(svm_model, \"svm_fake_news_model.pkl\")\n",
    "print(\"Lưu mô hình Linear SVM hoàn tất.\")\n",
    "# ------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
